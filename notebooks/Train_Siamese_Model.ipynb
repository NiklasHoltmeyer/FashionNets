{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Train_Siamese_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1CkKf7yIqPf"
      },
      "source": [
        "job_worker_name = \"g_b3_33\"\n",
        "!pip uninstall -y fashion_nets\n",
        "!pip uninstall -y fashion_datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "zRy4SDO4EK-j"
      },
      "source": [
        "#@title Pip Installs & Imports\n",
        "#!pip uninstall -y fashion_nets\n",
        "!pip install -q git+https://github.com/NiklasHoltmeyer/FashionNets.git\n",
        "try: \n",
        "  from fashionnets.train_jobs.loader.job_loader import prepare_environment, load_job_settings, history_to_csv_string\n",
        "  from fashionnets.train_jobs.loader.model_loader import load_siamese_model_from_train_job\n",
        "except:\n",
        "  from fashionnets.train_jobs.loader.job_loader import prepare_environment, load_job_settings, history_to_csv_string\n",
        "  from fashionnets.train_jobs.loader.model_loader import load_siamese_model_from_train_job"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJs0EWXV6MUy",
        "cellView": "form"
      },
      "source": [
        "#@title Prepare Environment. Download Datasets\n",
        "from fashionnets.train_jobs.loader.job_loader import add_back_bone_to_train_job\n",
        "\n",
        "environment, training_job_cfg = prepare_environment(job_worker_name, debugging=False)\n",
        "import kaggle #<- Requires Secrets, therefore prepare_environment needs to be run before\n",
        "kaggle.api.authenticate()\n",
        "\n",
        "kaggle_downloader = kaggle.api.dataset_download_files #<- sadly needs to be injected\n",
        "\n",
        "train_job = load_job_settings(environment=environment, training_job_cfg=training_job_cfg, kaggle_downloader=kaggle_downloader)\n",
        "\n",
        "job_settings = add_back_bone_to_train_job(environment=environment, **training_job_cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrQChkAAXbUr"
      },
      "source": [
        "siamese_model, init_epoch, _callbacks = load_siamese_model_from_train_job(load_weights=True, **train_job)\n",
        "print(\"init_epoch\", init_epoch)\n",
        "print(\"Callbacks\", _callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRdsVV3tZ3YK"
      },
      "source": [
        "from fashionnets.train_jobs.loader.dataset_loader import build_dataset_hard_pairs_deep_fashion\n",
        "import tensorflow as tf\n",
        "\n",
        "historys = []\n",
        "build_frequency = 5\n",
        "\n",
        "for idx in range(train_job[\"epochs\"] // build_frequency):\n",
        "    init_epoch_local = idx * build_frequency\n",
        "    epochs = init_epoch_local + build_frequency\n",
        "    \n",
        "    if init_epoch_local < init_epoch:\n",
        "        continue\n",
        "\n",
        "    print(init_epoch_local)\n",
        "    \n",
        "    dataset = build_dataset_hard_pairs_deep_fashion(siamese_model, job_settings)\n",
        "\n",
        "    history = siamese_model.fit(dataset[\"train\"], \n",
        "                            epochs=epochs, \n",
        "                            validation_data=dataset[\"val\"], \n",
        "                            callbacks = _callbacks,\n",
        "                            initial_epoch=init_epoch) \n",
        "    historys.append(history)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrTv2VFi6Yrk"
      },
      "source": [
        "_callbacks[-1].on_epoch_end(100000, None) #<- force reupload all Zips"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}